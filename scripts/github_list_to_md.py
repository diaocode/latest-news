import os
import re
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import requests
from datetime import datetime, timezone
from datetime import timedelta
import pytz
from utils_gemini import GeminiApiUtils
from github_trending import get_trending_repos
from typing import List
import shutil

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# Initialize AI API utils
ai_utils = GeminiApiUtils()

# é…ç½®å¸¸é‡
OUTPUT_DIR = 'github_daily'  # è¾“å‡ºç›®å½•
FILE_PREFIX = 'Github-hot'  # æ–‡ä»¶åå‰ç¼€
FILE_EXT = '.md'  # æ–‡ä»¶æ‰©å±•å

class DataItem:
    def __init__(self, id: str, word: str, num: int, label_name: str, description: str, 
                 daily_stars: str = '0', built_by: List[str] = None, **kwargs):
        self.word = word
        self.num = num
        self.label_name = label_name
        self.description = description
        self.daily_stars = daily_stars
        self.built_by = built_by or []

    def convert_to_beijing_time(self, utc_time_str: str) -> str:
        """å°†UTCæ—¶é—´è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´"""
        try:
            # First try the original format
            utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%SZ')
        except ValueError:
            # If that fails, try the new format
            utc_time = datetime.strptime(utc_time_str, '%Y-%m-%d %H:%M:%S')
        beijing_tz = pytz.timezone('Asia/Shanghai')
        beijing_time = utc_time.replace(tzinfo=pytz.utc).astimezone(beijing_tz)
        return beijing_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %p%I:%M (åŒ—äº¬æ—¶é—´)')

    def to_markdown(self, rank: int) -> str:
        """è¿”å›æ•°æ®çš„Markdownæ ¼å¼"""
        # Only show label_name if it's not empty
        encoded_word = self.word.replace(' ', '%20')
        title = f"#### {rank}. [{self.word}](https://www.bing.com/search?q={encoded_word})"
        if self.label_name:
            title += f" ({self.label_name}) "
        # title += "\n"
        
        return (
            f"{title} **çƒ­åº¦**ï¼š{self.num}\n"
        )

def fetch_data(current_time):
    """
    Fetch trending repositories using github_trending methods
    
    Args:
        current_time (datetime): Current time (not used in this implementation)
    
    Returns:
        list: A list of trending repositories
    """
    # Use the get_trending_repos method from github_trending
    trending_repos = get_trending_repos({
        'since': 'daily'  # Fetch daily trending repositories
    })
    
    # Transform the data to match the existing DataItem structure
    result_list = []
    for idx, repo in enumerate(trending_repos, 1):
        data_item = DataItem(
            id=str(idx),
            word=repo.get('owner', 'Unknown') + '/' + repo.get('repo', 'Unknown'),
            num=int(repo.get('stars', '0').replace(',', '')),
            label_name=repo.get('language', ''),
            description=repo.get('desc', ''),
            daily_stars=repo.get('daily_stars', '0'),
            built_by=repo.get('built_by', [])
        )
        result_list.append(data_item)
    
    return result_list

def generate_markdown(result_list, current_time, language='zh') -> str:
    """
    Generate Markdown content for GitHub trending repositories
    
    Args:
        result_list (list): List of trending repositories
        current_time (datetime): Current time for generating the markdown
        language (str): Language of the markdown content, either 'zh' or 'en'
    
    Returns:
        str: Markdown formatted content
    """
    # Prepare time-related information
    bj_time_str = current_time.strftime('%Y-%m-%d %H:%M')
    
    # Choose title and description based on language
    if language == 'zh':
        title = f"ğŸš€ GitHub | {bj_time_str}"
        slug = f"github-trending-{bj_time_str}"
        keywords = "GitHub, è¶‹åŠ¿, å¼€æºé¡¹ç›®"
        description = "ğŸŒŸ æ¯æ—¥ç²¾é€‰ GitHub æœ€çƒ­é—¨çš„å¼€æºé¡¹ç›®ï¼ŒåŠ©ä½ æŒæ¡æŠ€æœ¯è„‰æï¼"
        tags = "GitHub, å¼€æº, è¶‹åŠ¿"
        header = "## ğŸ”¥ ä»Šæ—¥ GitHub çƒ­é—¨ä»“åº“ä¸€è§ˆ"
        header_description = "ä»¥ä¸‹æ˜¯ä»Šæ—¥æœ€å—æ¬¢è¿çš„å¼€æºé¡¹ç›®ï¼Œæ¯ä¸€ä¸ªéƒ½å€¼å¾—ä½ å…³æ³¨ï¼ğŸ’¡"
        daily_stars_text = "ä»Šæ—¥æ–°å¢"
        language_text = "è¯­è¨€"
        description_text = "æè¿°"
        built_by_text = "Built by"
        no_description = "æš‚æ— æè¿°"
        no_contributors = "æš‚æ— è´¡çŒ®è€…ä¿¡æ¯"
        closing_header = "## ğŸŒˆ æ¯æ—¥å¼€æºä¹‹æ—…"
        closing_description = "å¼€æºä¸–ç•Œï¼Œæ— é™å¯èƒ½ï¼æŒç»­å…³æ³¨ï¼Œå‘ç°æ›´å¤šç²¾å½©é¡¹ç›®ã€‚"
        generated_by = "æœ¬æŠ¥å‘Šç”± GitHub è¶‹åŠ¿çˆ¬è™«è‡ªåŠ¨ç”Ÿæˆ ğŸ¤–"
    else:  # English
        title = f"ğŸš€ GitHub | {bj_time_str}"
        slug = f"github-trending-{bj_time_str}"
        keywords = "GitHub, Trending, Open Source Projects"
        description = "ğŸŒŸ Daily curated GitHub's most popular open-source projects to help you stay on the pulse of technology!"
        tags = "GitHub, Open Source, Trending"
        header = "## ğŸ”¥ Today's GitHub Hot Repositories"
        header_description = "Here are today's most popular open-source projects, each worth your attention! ğŸ’¡"
        daily_stars_text = "Today's Stars"
        language_text = "Language"
        description_text = "Description"
        built_by_text = "Built by"
        no_description = "No description available"
        no_contributors = "No contributor information"
        closing_header = "## ğŸŒˆ Daily Open Source Journey"
        closing_description = "Open source world, infinite possibilities! Keep following, discover more amazing projects."
        generated_by = "This report is automatically generated by GitHub Trending Crawler ğŸ¤–"
    
    # Start markdown content with a fun header
    markdown_content = f"""---
title: {title}
slug: {slug}
keywords: [{keywords}]
description: {description}
authors: [yangshun]
date: {current_time.strftime('%Y-%m-%d %H:%M:%S')}
tags: [{tags}]
---

{header}

> {header_description}

"""
    
    # Language emojis dictionary
    language_emojis = {
        'Python': 'ğŸ', 
        'JavaScript': 'âœ¨', 
        'TypeScript': 'ğŸŒ', 
        'Rust': 'ğŸ¦€', 
        'Ruby': 'ğŸ’', 
        'Java': 'â˜•', 
        'Go': 'ğŸš¦', 
        'C++': 'ğŸ”§', 
        'Dart': 'ğŸ¯',
        'Unknown': 'â“'
    }
    
    # Add repositories to markdown content
    for rank, result in enumerate(result_list, 1):
        # Choose an emoji based on the language or repository type
        lang_emoji = language_emojis.get(result.label_name, 'ğŸ“¦')
        
        # Create a star rating emoji
        star_rating = 'â­' * min(5, max(1, int(len(str(result.num)) / 3)))
        
        # Remove spaces from the repository name for the URL
        url_safe_repo_name = result.word.replace(' ', '')
        github_url = f"https://github.com/{url_safe_repo_name}"
        
        # Generate contributors with GitHub profile links
        if result.built_by:
            contributors_links = [
                f"[{contributor}](https://github.com/{contributor})"
                for contributor in result.built_by
            ]
            contributors_str = ', '.join(contributors_links)
        else:
            contributors_str = no_contributors
        
        markdown_content += f"""### {rank}. {lang_emoji} [{result.word}]({github_url})

{star_rating} **Stars**: `{result.num}`   â€¢   ğŸ“ˆ **{daily_stars_text}**: `{result.daily_stars}`   â€¢   **{language_text}**ï¼š`{result.label_name or 'æœªçŸ¥'}`

ğŸ“ **{description_text}**ï¼š{result.description or no_description}

ğŸ¤ **{built_by_text}**ï¼š{contributors_str}

---

"""
    
    # Add a closing section
    markdown_content += f"""{closing_header}

> {closing_description}

*{generated_by}*
"""
    
    return markdown_content

def generate_article_content(current_time=None):
    """
    Main function to generate GitHub trending markdown article
    
    Args:
        current_time (datetime, optional): Time to use for the article. Defaults to current time.
    
    Returns:
        str: Generated markdown content
    """
    # Use current time if not provided
    if current_time is None:
        current_time = datetime.now(timezone(timedelta(hours=8)))
    
    # Fetch trending repositories
    result_list = fetch_data(current_time)
    
    # Ensure output directory exists
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Generate filename
    filename = f"{OUTPUT_DIR}/{current_time.strftime('%Y-%m-%d')}-{FILE_PREFIX}-{current_time.strftime('%H')}{FILE_EXT}"
    
    # Generate Chinese markdown
    markdown_content_zh = generate_markdown(result_list, current_time, language='zh')
    
    # Write Chinese markdown content to file
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(markdown_content_zh)
    
    # Generate English markdown
    markdown_content_en = generate_markdown(result_list, current_time, language='en')
    
    # Copy to i18n/en directory
    i18n_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'i18n', 'en', 'docusaurus-plugin-content-blog-github-daily')
    os.makedirs(i18n_dir, exist_ok=True)
    
    # Generate English filename in i18n directory
    i18n_filename = os.path.join(i18n_dir, os.path.basename(filename))
    
    # Write English markdown content to i18n directory
    with open(i18n_filename, 'w', encoding='utf-8') as f:
        f.write(markdown_content_en)
    
    return markdown_content_zh

def write_to_md_file(content: str) -> str:
    """
    å°†ç”Ÿæˆçš„æ–‡ç« å†…å®¹å†™å…¥markdownæ–‡ä»¶
    :param content: markdownæ ¼å¼çš„æ–‡ç« å†…å®¹
    """
    try:
        # ä»å†…å®¹ä¸­æå–æ ‡é¢˜
        title_match = re.search(r'slug: (.*?)\n', content)
        if not title_match:
            print("æ— æ³•ä»å†…å®¹ä¸­æå–æ ‡é¢˜")
            return
            
        # è·å–æ ‡é¢˜å¹¶è½¬æ¢ä¸ºè‹±æ–‡æ–‡ä»¶åæ ¼å¼
        title = title_match.group(1)
        file_name = f"{title.lower().replace(' ', '-')}.md"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        output_dir = 'blog/shortstory'
        os.makedirs(output_dir, exist_ok=True)
        
        # æ·»åŠ æˆªæ–­æ ‡è®°
        content = insert_truncate_marker(content)
        
        # å†™å…¥æ–‡ä»¶
        file_path = os.path.join(output_dir, file_name)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"æ–‡ç« å·²ä¿å­˜åˆ°: {file_path}")
        return file_name
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")


def write_to_en_md_file(content: str):
    """
    Write the generated English Weibo hot search content to markdown file in the i18n/en directory
    :param content: markdown formatted English content for Weibo hot search
    """
    # Extract the date and hour from the content
    match = re.search(r'date: (\d{4}-\d{2}-\d{2}) (\d{2}):00:00', content)
    if not match:
        print("Could not find date in content")
        return
    
    date_str = match.group(1)
    hour_str = match.group(2)
    
    # Ensure the output directory exists
    en_output_dir = os.path.join('i18n', 'en', 'docusaurus-plugin-content-blog-github-daily')
    os.makedirs(en_output_dir, exist_ok=True)
    
    # Generate the file name
    file_name = os.path.join(en_output_dir, f"{date_str}-{FILE_PREFIX}-{hour_str}{FILE_EXT}")
    
    # æ·»åŠ æˆªæ–­æ ‡è®°
    content = insert_truncate_marker(content)
    
    # Write content to file
    with open(file_name, 'w', encoding='utf-8') as file:
        file.write(content)
    print(f"English Weibo hot search file {file_name} generated successfully.")

def write_to_en_article_file(content: str, article_file_name: str):
    """
    Write the generated English article content to markdown file in the i18n/en directory
    :param content: markdown formatted English article content
    :param article_file_name: original Chinese article file name to maintain consistency
    """
    try:
        # Get the base filename without the directory path
        base_filename = os.path.basename(article_file_name)
        
        # Ensure the output directory exists
        en_output_dir = os.path.join('i18n', 'en', 'docusaurus-plugin-content-blog', 'shortstory')
        os.makedirs(en_output_dir, exist_ok=True)
        
        # Generate the file name using the same base filename
        file_name = os.path.join(en_output_dir, base_filename)
        
        # æ·»åŠ æˆªæ–­æ ‡è®°
        content = insert_truncate_marker(content)

        # Write content to file
        with open(file_name, 'w', encoding='utf-8') as file:
            file.write(content)
        print(f"English article file {file_name} generated successfully.")
    except Exception as e:
        print(f"Error saving English article file: {e}")

def insert_truncate_marker(content: str) -> str:
    """åœ¨æ–‡ç« å†…å®¹çš„ç¬¬12è¡Œä½ç½®å•ç‹¬å†™å…¥ä¸€è¡Œæ ‡è®°ï¼š<!-- truncate -->
    Args:
        content: åŸå§‹æ–‡ç« å†…å®¹
    Returns:
        str: æ’å…¥æ ‡è®°åçš„æ–‡ç« å†…å®¹
    """
    lines = content.split('\n')
    if len(lines) >= 12:
        lines.insert(12, '<!-- truncate -->')
    return '\n'.join(lines)

def main():
    """
    Main function to run the GitHub trending scraper and generate markdown
    """
    # è·å–å½“å‰æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
    current_time = datetime.now(timezone(timedelta(hours=8)))
    bj_time_str = current_time.strftime('%Y-%m-%d_%H')
    print(f"bj_time_str={bj_time_str}")

    # ç”ŸæˆMarkdownæ–‡ä»¶
    markdown_content = generate_article_content(current_time)
    print(f"markdown_content=\n{markdown_content}")

if __name__ == "__main__":
    main()
